{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOLjYkXIbQ8f6DkWb/vHaKF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pattichis/AdvancedPython/blob/main/FastPython2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fast Python Execution using NumPy, Numba, GPUs, and AI prompting\n",
        "The example demonstrates the use of for-loops, versus the use of NumPy, Numba on CPUs, and GPUs.\n",
        "\n",
        "For the GPU example to run, click on Runtime and select a GPU.\n",
        "\n",
        "\n",
        "Here is a typical speedup:\n",
        "```\n",
        "Problem size: N=1000, D=50\n",
        "--------------------------------------------------\n",
        "Pure Python: 4.682 s\n",
        "NumPy:       0.028 s (Speedup: 164.6x)\n",
        "Numba:       0.025 s (Speedup: 188.8x)\n",
        "Numba CUDA:  0.006 s (Speedup: 803.0x)\n",
        "All speedup tests passed! (min_speedup = 100.0x)\n",
        "```\n",
        "\n",
        "Note: NumPy calculates A LOT more than Numba.\n",
        "\n",
        "The basic idea is to use a numba decorator:\n",
        "```\n",
        "import numba as nb\n",
        "\n",
        "@nb.njit(parallel=True, fastmath=True)\n",
        "def pairwise_dist_numba(X):\n",
        "```\n",
        "\n",
        "[Important paper to read (see section 2)](https://ieeexplore.ieee.org/document/11186485)<br>\n",
        "\n",
        "[Cuda link](https://docs.nvidia.com/cuda/cuda-programming-guide/02-basics/writing-cuda-kernels.html#writing-cuda-kernels-sm-resource-example)\n"
      ],
      "metadata": {
        "id": "Pr8yJwAxUnlF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3759f508"
      },
      "source": [
        "## Pseudocode for Pairwise Distance Calculation\n",
        "\n",
        "```\n",
        "function pairwise_distance(data_matrix):\n",
        "    num_rows = number of rows in data_matrix\n",
        "    distance_matrix = create an empty matrix of size (num_rows x num_rows) initialized with zeros\n",
        "\n",
        "    for each row i from 0 to num_rows - 1:\n",
        "        for each row j from 0 to num_rows - 1:\n",
        "            squared_difference_sum = 0\n",
        "            for each element k in the rows:\n",
        "                difference = data_matrix[i][k] - data_matrix[j][k]\n",
        "                squared_difference_sum = squared_difference_sum + (difference * difference)\n",
        "            distance_matrix[i][j] = squared_difference_sum\n",
        "\n",
        "    return distance_matrix\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example code"
      ],
      "metadata": {
        "id": "8aMjSmSvhMtd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S20-_8GfWfoC",
        "outputId": "2532a1a0-dfe6-47a3-9519-a9aceac759f3"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import numba as nb\n",
        "from numba import cuda\n",
        "\n",
        "# ----------------------------\n",
        "# Implementations\n",
        "# ----------------------------\n",
        "\n",
        "def pairwise_dist_python(X):\n",
        "    n = len(X)\n",
        "    d = len(X[0])\n",
        "    D = [[0.0] * n for _ in range(n)]\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            s = 0.0\n",
        "            for k in range(d):\n",
        "                diff = X[i][k] - X[j][k]\n",
        "                s += diff * diff\n",
        "            D[i][j] = s\n",
        "    return D\n",
        "\n",
        "\n",
        "def pairwise_dist_numpy(X):\n",
        "    G = X @ X.T\n",
        "    sq_norms = np.diag(G)\n",
        "    return sq_norms[:, None] - 2 * G + sq_norms[None, :]\n",
        "\n",
        "\n",
        "@nb.njit(parallel=True, fastmath=True)\n",
        "def pairwise_dist_numba(X):\n",
        "    n, d = X.shape\n",
        "    D = np.zeros((n, n))\n",
        "    for i in nb.prange(n):\n",
        "        for j in range(n):\n",
        "            s = 0.0\n",
        "            for k in range(d):\n",
        "                diff = X[i, k] - X[j, k]\n",
        "                s += diff * diff\n",
        "            D[i, j] = s\n",
        "    return D\n",
        "\n",
        "@cuda.jit\n",
        "def pairwise_dist_numba_cuda_kernel(X, D):\n",
        "    # Global row and column indices for the current thread in the D matrix\n",
        "    #  This is the setup for a 2-D indexing of threads on Cuda.\n",
        "    #  All threads will run the same Cuda kernel listed here.\n",
        "    #  Computes one 2-D index of D at a time.\n",
        "    # printing breaks the kernel.\n",
        "    row_idx, col_idx = cuda.grid(2)\n",
        "\n",
        "    # Check bounds to avoid out-of-bounds memory access if grid size > actual matrix size\n",
        "    if row_idx >= D.shape[0] or col_idx >= D.shape[1]:\n",
        "        return\n",
        "\n",
        "    # Thread indices within the block\n",
        "    #   These are local variables of the running thread.\n",
        "    #   Assuming that cuda.threadIdx comes from the index of running thread.\n",
        "    tx = cuda.threadIdx.x\n",
        "    ty = cuda.threadIdx.y\n",
        "\n",
        "    # Block dimensions\n",
        "    #    These must be initialized before calling this function. How?\n",
        "    blockDim_x = cuda.blockDim.x\n",
        "    blockDim_y = cuda.blockDim.y\n",
        "\n",
        "    # Block's starting global row and column indices\n",
        "    #  This defines the start of a single block that will be processed by a single core.\n",
        "    block_start_row = cuda.blockIdx.x * blockDim_x\n",
        "    block_start_col = cuda.blockIdx.y * blockDim_y\n",
        "\n",
        "    # Feature dimension (D in NxD)\n",
        "    D_features = X.shape[1]\n",
        "\n",
        "    # Define shared memory arrays\n",
        "    # s_X_row_tile will store X[block_start_row + tx, :] for all tx in the block\n",
        "    # s_X_col_tile will store X[block_start_col + ty, :] for all ty in the block\n",
        "    # The shape is (block_dimension, D_features)\n",
        "    s_X_row_tile = cuda.shared.array(shape=(16, 50), dtype=X.dtype) # Using 16, 50 explicitly for clarity\n",
        "    s_X_col_tile = cuda.shared.array(shape=(16, 50), dtype=X.dtype)\n",
        "\n",
        "    # Cooperative loading into shared memory\n",
        "    # Each thread in the block will help load data into shared memory.\n",
        "    # For s_X_row_tile: thread (tx, 0) loads X[global_row, :] into s_X_row_tile[tx, :]\n",
        "    if ty == 0 and block_start_row + tx < X.shape[0]:\n",
        "        for k_feat in range(D_features):\n",
        "            s_X_row_tile[tx, k_feat] = X[block_start_row + tx, k_feat]\n",
        "\n",
        "    # For s_X_col_tile: thread (0, ty) loads X[global_col, :] into s_X_col_tile[ty, :]\n",
        "    if tx == 0 and block_start_col + ty < X.shape[0]:\n",
        "        for k_feat in range(D_features):\n",
        "            s_X_col_tile[ty, k_feat] = X[block_start_col + ty, k_feat]\n",
        "\n",
        "    # Synchronize threads to ensure all shared memory loads are complete before computation\n",
        "    # 2. Straight-forward but makes the point about memory access into shared memory.\n",
        "    # Marios: ALL threads complete their memory copies.\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    # Compute the squared Euclidean distance using shared memory\n",
        "    # 1. START your analysis here to establish notation. Then go backwards.\n",
        "    s = 0.0\n",
        "    if row_idx < X.shape[0] and col_idx < X.shape[0]: # Final check for valid indices\n",
        "        for k_feat in range(D_features):\n",
        "            # Access shared memory for computation\n",
        "            diff = s_X_row_tile[tx, k_feat] - s_X_col_tile[ty, k_feat]\n",
        "            s += diff * diff\n",
        "\n",
        "        D[row_idx, col_idx] = s\n",
        "\n",
        "\n",
        "def pairwise_dist_numba_cuda(X):\n",
        "    # Copy data to device\n",
        "    # Kevin: Copies to global memory in Cuda.\n",
        "    # GPU: Global + shared + local (local done internally?)\n",
        "    # Verify what .to_device() and device_array() mean\n",
        "    X_device = cuda.to_device(X)\n",
        "    D_device = cuda.device_array((X.shape[0], X.shape[0]), dtype=X.dtype)\n",
        "    print(\" \")\n",
        "    print(f\"GPU: X_device shape =  {X_device.shape} and D_device shape = {D_device.shape}\")\n",
        "\n",
        "    # Configure the blocks and grids\n",
        "    # Kevin: Every block will have 16*16 threads.\n",
        "    threadsperblock = (16, 16) #\n",
        "    blockspergrid_x = (X.shape[0] + threadsperblock[0] - 1) // threadsperblock[0]\n",
        "    blockspergrid_y = (X.shape[0] + threadsperblock[1] - 1) // threadsperblock[1]\n",
        "    blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
        "\n",
        "    # See everything:\n",
        "    print(f\"threads per block = {threadsperblock}\")\n",
        "    print(f\"blocks per grid x = {blockspergrid_x}\")\n",
        "    print(f\"blocks per grid y = {blockspergrid_y}\")\n",
        "    print(f\"blocks per grid   = {blockspergrid}\")\n",
        "\n",
        "    # Launch the kernel\n",
        "    # FINAL. We need to cover this function call here. It looks strange and 2-D.\n",
        "    # How do we derive all of the variables everything from here?\n",
        "    pairwise_dist_numba_cuda_kernel[blockspergrid, threadsperblock](X_device, D_device)\n",
        "\n",
        "    # Copy result back to host\n",
        "    return D_device.copy_to_host()\n",
        "\n",
        "# ----------------------------\n",
        "# Timing helper\n",
        "# ----------------------------\n",
        "\n",
        "def timeit(fn, *args, repeat=3, warmup=False):\n",
        "    if warmup:\n",
        "        fn(*args)\n",
        "    times = []\n",
        "    for _ in range(repeat):\n",
        "        t0 = time.perf_counter()\n",
        "        fn(*args)\n",
        "        times.append(time.perf_counter() - t0)\n",
        "    return min(times)\n",
        "\n",
        "# ----------------------------\n",
        "# Benchmark\n",
        "# ----------------------------\n",
        "\n",
        "n, d = 1000, 50\n",
        "np.random.seed(0)\n",
        "X_np = np.random.randn(n, d).astype(np.float64)\n",
        "X_py = X_np.tolist()\n",
        "\n",
        "print(f\"Problem size: N={n}, D={d}\")\n",
        "print(\"--------------------------------------------------\")\n",
        "\n",
        "# Warm up Numba (compilation happens here) - Redundant if warmup=True in timeit, but harmless.\n",
        "pairwise_dist_numba(X_np)\n",
        "\n",
        "# Warm up Numba CUDA (compilation happens here) - Redundant if warmup=True in timeit, but harmless.\n",
        "# It's important to pass a copy to avoid side effects if the function modifies the input\n",
        "if cuda.is_available():\n",
        "    pairwise_dist_numba_cuda(X_np)\n",
        "\n",
        "t_python = timeit(pairwise_dist_python, X_py, repeat=1, warmup=True)\n",
        "t_numpy = timeit(pairwise_dist_numpy, X_np, warmup=True)\n",
        "t_numba = timeit(pairwise_dist_numba, X_np, warmup=True)\n",
        "\n",
        "print(f\"Pure Python: {t_python:.3f} s\")\n",
        "print(f\"NumPy:       {t_numpy:.3f} s (Speedup: {t_python/t_numpy:.1f}x)\")\n",
        "print(f\"Numba:       {t_numba:.3f} s (Speedup: {t_python/t_numba:.1f}x)\")\n",
        "\n",
        "min_speedup = 100.0 # Define minimal speedup threshold\n",
        "\n",
        "assert t_python / t_numpy >= min_speedup, f\"NumPy speedup failed: {t_python / t_numpy:.1f}x < {min_speedup}x\"\n",
        "assert t_python / t_numba >= min_speedup, f\"Numba speedup failed: {t_python / t_numba:.1f}x < {min_speedup}x\"\n",
        "\n",
        "if cuda.is_available():\n",
        "    t_numba_cuda = timeit(pairwise_dist_numba_cuda, X_np, warmup=True)\n",
        "    print(f\"Numba CUDA:  {t_numba_cuda:.3f} s (Speedup: {t_python/t_numba_cuda:.1f}x)\")\n",
        "    assert t_python / t_numba_cuda >= min_speedup, f\"Numba CUDA speedup failed: {t_python / t_numba_cuda:.1f}x < {min_speedup}x\"\n",
        "    print(f\"All speedup tests passed! (min_speedup = {min_speedup}x)\")\n",
        "else:\n",
        "    print(\"Numba CUDA:  GPU not available, skipping CUDA benchmark and speedup test.\")\n",
        "    print(f\"NumPy and Numba speedup tests passed! (min_speedup = {min_speedup}x)\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem size: N=1000, D=50\n",
            "--------------------------------------------------\n",
            " \n",
            "GPU: X_device shape =  (1000, 50) and D_device shape = (1000, 1000)\n",
            "threads per block = (16, 16)\n",
            "blocks per grid x = 63\n",
            "blocks per grid y = 63\n",
            "blocks per grid   = (63, 63)\n",
            "Pure Python: 3.577 s\n",
            "NumPy:       0.012 s (Speedup: 304.5x)\n",
            "Numba:       0.006 s (Speedup: 553.0x)\n",
            " \n",
            "GPU: X_device shape =  (1000, 50) and D_device shape = (1000, 1000)\n",
            "threads per block = (16, 16)\n",
            "blocks per grid x = 63\n",
            "blocks per grid y = 63\n",
            "blocks per grid   = (63, 63)\n",
            " \n",
            "GPU: X_device shape =  (1000, 50) and D_device shape = (1000, 1000)\n",
            "threads per block = (16, 16)\n",
            "blocks per grid x = 63\n",
            "blocks per grid y = 63\n",
            "blocks per grid   = (63, 63)\n",
            " \n",
            "GPU: X_device shape =  (1000, 50) and D_device shape = (1000, 1000)\n",
            "threads per block = (16, 16)\n",
            "blocks per grid x = 63\n",
            "blocks per grid y = 63\n",
            "blocks per grid   = (63, 63)\n",
            " \n",
            "GPU: X_device shape =  (1000, 50) and D_device shape = (1000, 1000)\n",
            "threads per block = (16, 16)\n",
            "blocks per grid x = 63\n",
            "blocks per grid y = 63\n",
            "blocks per grid   = (63, 63)\n",
            "Numba CUDA:  0.003 s (Speedup: 1239.5x)\n",
            "All speedup tests passed! (min_speedup = 100.0x)\n"
          ]
        }
      ]
    }
  ]
}